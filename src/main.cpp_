#include <cstdio>
#include <iostream>
#include <array>
#include <tuple>

template <class T>
class dual_number {
private:
    T x;
    T x_dash;

public:
    dual_number() : dual_number(0, 0) { }
    dual_number(const T x, const T x_dash) : x(x), x_dash(x_dash) { }

    T &value() { return x; }
    T &diff() { return x_dash; }
    const T &value() const { return x; }
    const T &diff() const { return x_dash; }

    template <class U1, class U2>
    static inline auto add(const dual_number<U1> &a, const dual_number<U2> &b) {
        return dual_number<decltype(a.x + b.x)>(a.x + b.x, a.x_dash + b.x_dash); }
    template <class U1, class U2>
    static inline auto sub(const dual_number<U1> &a, const dual_number<U2> &b) {
        return dual_number<decltype(a.x - b.x)>(a.x - b.x, a.x_dash - b.x_dash); }
    template <class U1, class U2>
    static inline auto mul(const dual_number<U1> &a, const dual_number<U2> &b) {
        return dual_number<decltype(a.x * b.x)>(a.x * b.x, a.x_dash * b.x + a.x * b.x_dash); }
    template <class U1, class U2>
    static inline auto div(const dual_number<U1> &a, const dual_number<U2> &b) {
        return dual_number<decltype(a.x / b.x)>(a.x / b.x, (a.x_dash * b.x - a.x * b.x_dash) / (b.x * b.x)); }
};

// 多次元 tensor<int, 1, 2, 3> a
template <typename T, std::size_t... Ns>
struct index_reverse_for_array;
template <typename T, std::size_t N, std::size_t... Ns>
struct index_reverse_for_array<T, N, Ns...> { using type = std::array<typename index_reverse_for_array<T, Ns...>::type, N>; };
template <typename T, std::size_t N>
struct index_reverse_for_array<T, N> { using type = std::array<T, N>; };
template <class T, std::size_t... Ns> using tensor = typename index_reverse_for_array<T, Ns...>::type;

template <class T, std::size_t... Ns>
class layer {
    tensor<T, Ns...> unit;

public:
    layer() : unit() { }

    template <class P, class U, std::size_t... Ms>
    layer(const P &w, const tensor<U, Ms...> &x) : unit() { propagate(w, x); }

    template <class P, class U, std::size_t... Ms>
    void propagate(const P &w, const tensor<U, Ms...> &x) {
        unit = w.product(x); }

    void set(const tensor<T, Ns...> &x) {
        // 代入処理
    }
    auto &get() {
        return unit; }
    const auto &get() const {
        return unit; }
};

template <class T, class U> class fully_connection;
template <class T, std::size_t... Ns, class U, std::size_t... Ms>
class fully_connection<layer<T, Ns...>, layer<U, Ms...>> {
    tensor<T, Ns..., Ms...> w;
    tensor<T, Ms...> b;

public:
    fully_connection() : w() { }
    layer<U, Ms...> product(const layer<T, Ns...> &x) {
        // 伝播
    }
};

template <class T, class U> class max;
template <class T, std::size_t... Ns, class U>
class max<layer<T, Ns...>, layer<U>> {
public:
    max() { }
    layer<U> product(const layer<T, Ns...> &x) {
        // 伝播
    }
};

class pooling;
class convolution;
class sigmoid;
class ReLU;

template <typename T, typename U>
struct marge_tuple_parameter;
template <typename... Ts, typename... Us>
struct marge_tuple_parameter<std::tuple<Ts...>, std::tuple<Us...>> { using type = std::tuple<Ts..., Us...>; };
template <typename... Ts>
struct parameter_splitter;
template <typename T1, typename T2, typename... Ts>
struct parameter_splitter<T1, T2, Ts...> {
    using odd = typename marge_tuple_parameter<std::tuple<T1>, typename parameter_splitter<Ts...>::odd>::type;
    using even = typename marge_tuple_parameter<std::tuple<T2>, typename parameter_splitter<Ts...>::even>::type;
    static constexpr std::size_t size = parameter_splitter<Ts...>::size + 1; };
template <typename T1, typename T2, typename T3>
struct parameter_splitter<T1, T2, T3> {
    using odd = std::tuple<T1, T3>;
    using even = std::tuple<T2>;
    static constexpr std::size_t size = 2; };

template <class... Ts>
class network {
private:
    typename parameter_splitter<Ts...>::odd layers;
    typename parameter_splitter<Ts...>::even linkings;
    static constexpr std::size_t layer_number = parameter_splitter<Ts...>::size;

    template <std::size_t I>
    void propagate() {
        if (I >= layer_number - 1) return;
        std::get<I+1>(layers).propagate(std::get<I>(linkings), std::get<I>(layers));
        propagate<I+1>();
    }

public:
    network() { }

    template <class T, std::size_t... Ns>
    void propagate(const tensor<T, Ns...> &x) {
        std::get<0>(layers).set(x);
        propagate<0>();
    }
};

using namespace std;

int main() {
    network<layer<double, 10> , fully_connection<layer<double, 10>, layer<double, 1>> , layer<double, 1>> net;

    return 0;
}

